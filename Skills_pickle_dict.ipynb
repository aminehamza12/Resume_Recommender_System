{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin de générer le dictionnaire final pour le mapping , on a utilisé le dossier __Dicts__ ( dans le même dossier que ce Notebook ) .\n",
    "Le dossier __Dicts__ contient tous les dictionnaires des skills individuels *( sous la forme .npy de numpy )*  qu'on va rassembler dans un seul objet pickle qu'on pourra utiliser ultérieurement ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "#Initialisation du dictionnaire final\n",
    "dict = {}\n",
    "\n",
    "for filename in os.listdir(\"Dicts\"):     #Parcourir tous les fichiers du dossier Dicts\n",
    "    if filename.endswith(\".npy\"):        #Pour les fichiers d'extension .npy executer le traitement suivant :\n",
    "        a = np.load(\"Dicts/\"+filename,allow_pickle=True)       #Charger le fichier npy (dictionnaire particulier)  \n",
    "        a = np.append(a,filename[:-15])      #Ajouter le nom du dictionnaire au dictionnaire comme autre écriture possible du mot car il ne contenait que les ecritures érronées   \n",
    "        dict[filename[:-15]]=[a]             #Ajouter au dictionnaire final un enregistrement qui a la forme suivante : CLE : nom du fichier / VALEUR : le contenu du fichier qui est les écritures possibles saisies . \n",
    "ss = list(set(['nodeJS', 'Node', 'node.js', 'notejs', 'ODS', 'Nodejs', 'Node.js', 'Node JS', 'NodeJS', 'node-Red', 'Node.JS', 'node-red', 'Node js', 'NodeJs', 'Web Nodejs', 'nodejs', 'nodeJs', 'node js', 'Node-RED',\n",
    "        'Node.js']))\n",
    "ss\n",
    "dict[\"Node.js\"] = ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict.keys()\n",
    "l = []\n",
    "sn = []\n",
    "for elem in list(dict.keys()):\n",
    "    j = list(dict.keys())\n",
    "    j.remove(elem)\n",
    "    for part in dict[elem][0]:\n",
    "        for elem2 in j:\n",
    "            if part in dict[elem2][0]:\n",
    "                l.append(part)\n",
    "                sn.append((elem,elem2))\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skills_dict',\"wb\") as handle:\n",
    "    pickle.dump(dict,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('skills_dict',\"rb\") as handle:\n",
    "    b = pickle.load(handle)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML] *",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
